{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fd93b902",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn import svm, metrics\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from keras.utils import to_categorical\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4499e114",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ferre\\machine_learning\\Dataset_IA\\T_DEV_810_dataset\\test\n"
     ]
    }
   ],
   "source": [
    "current_dir= os.getcwd()\n",
    "folder_path = \"\"+ current_dir +\"\\\\test\"\n",
    "print(folder_path)\n",
    "ListimagesTest = []\n",
    "\n",
    "\n",
    "folder_path_train= \"\"+ current_dir +\"\\\\train\"\n",
    "ListimagesTrain = []\n",
    "\n",
    "\n",
    "nbImagesNORMALTest = 0\n",
    "nbImagesPNEUMONIATest = 0\n",
    "\n",
    "nbImagesNORMALTrain = 0\n",
    "nbImagesPNEUMONIATrain = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4fe439b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for filename in os.listdir(folder_path+'\\\\NORMAL'):\n",
    "   \n",
    "    if filename.endswith(\".jpg\") or filename.endswith(\".jpeg\") or filename.endswith(\".png\"):\n",
    "        # Ouvrir l'image et l'ajouter à la liste\n",
    "        img = cv2.imread(os.path.join(folder_path+'\\\\NORMAL', filename))\n",
    "        nbImagesNORMALTest +=1\n",
    "        ListimagesTest.append(img)\n",
    "for filename in os.listdir(folder_path+'\\\\PNEUMONIA'): \n",
    "    if filename.endswith(\".jpg\") or filename.endswith(\".jpeg\") or filename.endswith(\".png\"):\n",
    "        img = cv2.imread(os.path.join(folder_path+'\\\\PNEUMONIA', filename))\n",
    "        nbImagesPNEUMONIATest +=1\n",
    "        ListimagesTest.append(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8462dd22",
   "metadata": {},
   "outputs": [],
   "source": [
    "for filename in os.listdir(folder_path_train+'\\\\NORMAL'): \n",
    "    if filename.endswith(\".jpg\") or filename.endswith(\".jpeg\") or filename.endswith(\".png\"):\n",
    "        img = cv2.imread(os.path.join(folder_path_train+'\\\\NORMAL', filename))\n",
    "        nbImagesNORMALTrain+=1\n",
    "        ListimagesTrain.append(img)\n",
    "        \n",
    "for filename in os.listdir(folder_path_train+'\\\\PNEUMONIA'):   \n",
    "    if filename.endswith(\".jpg\") or filename.endswith(\".jpeg\") or filename.endswith(\".png\"): \n",
    "        img = cv2.imread(os.path.join(folder_path_train+'\\\\PNEUMONIA', filename))\n",
    "        nbImagesPNEUMONIATrain +=1\n",
    "        ListimagesTrain.append(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e69667cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "img0shape = (224, 224)\n",
    "ListimagesTestResize = []\n",
    "ListimagesTrainResize = []\n",
    "\n",
    "for img in ListimagesTest :\n",
    "    ListimagesTestResize.append(cv2.resize(img,img0shape))\n",
    "    \n",
    "    \n",
    "for img in ListimagesTrain :\n",
    "    ListimagesTrainResize.append(cv2.resize(img,img0shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6faddf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ListimagesTestNorm = []\n",
    "ListimagesTrainNorm = []\n",
    "\n",
    "\n",
    "for img in ListimagesTestResize:\n",
    "    ListimagesTestNorm.append(cv2.normalize(img, None, 0, 1.0, cv2.NORM_MINMAX, dtype=cv2.CV_32F))\n",
    "for img in ListimagesTrainResize:\n",
    "    ListimagesTrainNorm.append(cv2.normalize(img, None, 0, 1.0, cv2.NORM_MINMAX, dtype=cv2.CV_32F))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5f784fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "ListimagesTestNorm = np.array(ListimagesTestNorm).reshape(len(ListimagesTestNorm),224,224,3)\n",
    "ListimagesTrainNorm= np.array(ListimagesTrainNorm).reshape(len(ListimagesTrainNorm),224,224,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5694605b",
   "metadata": {},
   "outputs": [],
   "source": [
    "unTest = np.array(np.ones(nbImagesPNEUMONIATest))\n",
    "zeroTest = np.array(np.zeros(nbImagesNORMALTest))\n",
    "\n",
    "unTrain =np.array(np.ones(nbImagesPNEUMONIATrain))\n",
    "zeroTrain = np.array(np.zeros(nbImagesNORMALTrain))\n",
    "\n",
    "ListimagesTestNormResult = np.concatenate((zeroTest ,unTest) )\n",
    "ListimagesTrainNormResult = np.concatenate((zeroTrain ,unTrain) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b95b40d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(ListimagesTrainNormResult))\n",
    "print(len(ListimagesTrainNorm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72d08091",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras.layers as layers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b9e2f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Création du modèle\n",
    "model = tf.keras.Sequential()\n",
    "\n",
    "# Ajout des couches\n",
    "model.add(layers.Conv2D(filters=96, kernel_size=(11, 11), strides=(4, 4), activation='relu', input_shape=(224, 224, 3)))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.MaxPooling2D(pool_size=(3, 3), strides=(2, 2)))\n",
    "model.add(layers.Conv2D(filters=256, kernel_size=(5, 5), activation='relu', padding=\"same\"))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.MaxPooling2D(pool_size=(3, 3), strides=(2, 2)))\n",
    "model.add(layers.Conv2D(filters=384, kernel_size=(3, 3), activation='relu', padding=\"same\"))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.Conv2D(filters=384, kernel_size=(3, 3), activation='relu', padding=\"same\"))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.Conv2D(filters=256, kernel_size=(3, 3), activation='relu', padding=\"same\"))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.MaxPooling2D(pool_size=(3, 3), strides=(2, 2)))\n",
    "model.add(layers.GlobalAveragePooling2D())\n",
    "model.add(layers.Dense(units=4096, activation='relu'))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(units=4096, activation='relu'))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "# Compilation du modèle\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Affichage de la structure du modèle\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed944c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entraînement du modèle\n",
    "# Mélanger les données d'entraînement\n",
    "\n",
    "ListimagesTrainNorm = ListimagesTrainNorm\n",
    "ListimagesTrainNormResult = ListimagesTrainNormResult\n",
    "\n",
    "# Entraînement du modèle\n",
    "model.fit(ListimagesTrainNorm, ListimagesTrainNormResult, epochs=10, batch_size=32, validation_data=(ListimagesTestNorm, ListimagesTestNormResult))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "364d5f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(ListimagesTestNorm, ListimagesTestNormResult, verbose=0)\n",
    "print('Perte (loss) :', score[0])\n",
    "print('Précision (accuracy) :', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "128f3026",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y_pred = model.predict(ListimagesTestNorm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27325332",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ListimagesTestNormResult)\n",
    "print( y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bee6e1c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "disp = metrics.ConfusionMatrixDisplay.from_predictions(ListimagesTestNormResult, y_pred)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e821123",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25f5418e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
